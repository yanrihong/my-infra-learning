# Module 06: MLOps - Quiz

**Time Limit:** 35 minutes
**Passing Score:** 80% (24/30 questions)
**Coverage:** MLOps practices, CI/CD, model management

---

## Section 1: MLOps Fundamentals (5 questions)

### Q1. What is MLOps?

a) Machine Learning Operations
b) Model Learning Optimization
c) Multi-Level Operations
d) Managed Learning Platform

**Answer:** A

---

### Q2. How does MLOps differ from DevOps?

a) No difference
b) MLOps adds data versioning, model management, experiment tracking
c) MLOps is simpler
d) MLOps is only for Python

**Answer:** B

---

### Q3. What are the three key pillars of MLOps?

a) Code, containers, cloud
b) People, process, platform
c) Data, models, deployment
d) Training, testing, production

**Answer:** B

---

### Q4. What is the goal of MLOps?

a) Make ML development slower
b) Streamline ML model development and deployment
c) Eliminate data scientists
d) Increase complexity

**Answer:** B

---

### Q5. What is technical debt in ML systems?

a) Money owed for tools
b) Long-term costs from quick fixes and poor practices
c) Training costs
d) Cloud bills

**Answer:** B

---

## Section 2: Model Training and Experiment Tracking (6 questions)

### Q6. What is experiment tracking?

a) Tracking bugs
b) Recording model parameters, metrics, and artifacts
c) Tracking team members
d) Monitoring servers

**Answer:** B

---

### Q7. Which tool is commonly used for experiment tracking?

a) Git only
b) MLflow, Weights & Biases
c) Excel
d) Notepad

**Answer:** B

---

### Q8. What should you log during model training?

a) Nothing
b) Hyperparameters, metrics, model artifacts, code version
c) Only final accuracy
d) Team members

**Answer:** B

---

### Q9. What is hyperparameter tuning?

a) Tuning hardware
b) Searching for optimal model configuration values
c) Adjusting data
d) Code optimization

**Answer:** B

---

### Q10. What is the purpose of a model registry?

a) Legal registration
b) Centralized store for model versions and metadata
c) Model training
d) Data storage

**Answer:** B

---

### Q11. Why version ML models?

a) Not necessary
b) Track changes, enable rollback, reproduce results
c) Waste storage
d) Slow down deployment

**Answer:** B

---

## Section 3: CI/CD for ML (7 questions)

### Q12. What is CI/CD?

a) Container Integration/Deployment
b) Continuous Integration/Continuous Deployment
c) Cloud Infrastructure/Development
d) Code Integration/Debugging

**Answer:** B

---

### Q13. How does CI/CD for ML differ from software CI/CD?

a) No difference
b) Adds data validation, model testing, performance checks
c) It's simpler
d) No testing needed

**Answer:** B

---

### Q14. What should be tested in ML CI/CD pipelines?

a) Nothing
b) Code, data, model quality, infrastructure
c) Only unit tests
d) Only integration tests

**Answer:** B

---

### Q15. What is a model validation step in CI/CD?

a) Legal validation
b) Checking model meets quality thresholds before deployment
c) Syntax checking
d) User acceptance

**Answer:** B

---

### Q16. What is canary deployment?

a) Deploying to all users at once
b) Gradual rollout to subset of users first
c) Rolling back deployment
d) Testing in development only

**Answer:** B

---

### Q17. What is A/B testing in ML deployment?

a) Testing two code versions
b) Comparing two model versions with live traffic
c) Alphabet testing
d) Testing on development only

**Answer:** B

---

### Q18. What is shadow mode deployment?

a) Deploying at night
b) New model runs in parallel, predictions not served
c) Deleting old model
d) Testing on local machine

**Answer:** B

---

## Section 4: Model Monitoring (6 questions)

### Q19. What is model drift?

a) Model files moving
b) Model performance degrading over time
c) Network latency
d) Storage issues

**Answer:** B

---

### Q20. What are the two types of model drift?

a) Fast and slow
b) Data drift and concept drift
c) Good and bad
d) Training and inference

**Answer:** B

---

### Q21. What metrics should you monitor in production?

a) Nothing
b) Accuracy, latency, throughput, error rate, drift
c) Only accuracy
d) Only latency

**Answer:** B

---

### Q22. What is data drift?

a) Data corruption
b) Input data distribution changing over time
c) Slow data transfer
d) Missing data

**Answer:** B

---

### Q23. What is concept drift?

a) Forgetting concepts
b) Relationship between features and target changing
c) Conceptual errors
d) Documentation drift

**Answer:** B

---

### Q24. How often should you retrain models in production?

a) Never
b) Depends on drift detection and business requirements
c) Every hour
d) Only when system crashes

**Answer:** B

---

## Section 5: MLOps Tools and Practices (6 questions)

### Q25. What is MLflow?

a) Water flow model
b) Open-source MLOps platform
c) Cloud provider
d) Container orchestrator

**Answer:** B

---

### Q26. What is Kubeflow?

a) Water flow in Kubernetes
b) ML platform built on Kubernetes
c) Kubernetes alternative
d) Monitoring tool

**Answer:** B

---

### Q27. What is DVC (Data Version Control)?

a) Data validation check
b) Git-like version control for data and models
c) Data visualization tool
d) Database

**Answer:** B

---

### Q28. What is feature store used for in MLOps?

a) Storing model code
b) Centralized feature management and serving
c) Storing logs
d) Infrastructure storage

**Answer:** B

---

### Q29. What is the purpose of model serving infrastructure?

a) Model storage
b) Expose model for predictions at scale
c) Model training
d) Data collection

**Answer:** B

---

### Q30. What is the best practice for model deployment?

a) Deploy directly to production
b) Test in staging, gradual rollout, monitoring
c) Never deploy
d) Deploy without testing

**Answer:** B

---

## Answer Key

1. A   2. B   3. B   4. B   5. B
6. B   7. B   8. B   9. B   10. B
11. B  12. B  13. B  14. B  15. B
16. B  17. B  18. B  19. B  20. B
21. B  22. B  23. B  24. B  25. B
26. B  27. B  28. B  29. B  30. B

---

## Scoring

- **27-30 correct (90-100%)**: Excellent! MLOps expert
- **24-26 correct (80-89%)**: Good! Production-ready
- **21-23 correct (70-79%)**: Fair. Review practices
- **Below 21 (< 70%)**: Review module materials

---

**Next Module:** Module 07 - GPU Computing
