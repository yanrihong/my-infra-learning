FROM apache/airflow:2.8.0-python3.9

# Project 02: End-to-End MLOps Pipeline
# Airflow Docker image with custom dependencies

USER root

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    curl \
    vim \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

USER airflow

# Copy requirements file
COPY requirements.txt /requirements.txt

# Install Python dependencies
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r /requirements.txt

# Install additional Airflow providers
RUN pip install --no-cache-dir \
    apache-airflow-providers-docker \
    apache-airflow-providers-postgres \
    apache-airflow-providers-http

# Set working directory
WORKDIR /opt/airflow

# Create necessary directories
RUN mkdir -p /opt/airflow/dags /opt/airflow/logs /opt/airflow/plugins

# Copy DAGs and source code (will be mounted via volume in docker-compose)
# COPY dags /opt/airflow/dags
# COPY src /opt/airflow/src

ENV PYTHONPATH="${PYTHONPATH}:/opt/airflow/src"

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}" || exit 1
