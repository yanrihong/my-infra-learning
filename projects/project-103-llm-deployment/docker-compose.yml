version: '3.8'

# LLM Deployment Platform - Docker Compose Configuration
# This setup includes all services needed for production LLM deployment with RAG

services:
  # ============================================================================
  # Vector Database - Milvus (for RAG)
  # ============================================================================
  etcd:
    container_name: milvus-etcd
    image: quay.io/coreos/etcd:v3.5.5
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3

  minio:
    container_name: milvus-minio
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    ports:
      - "9001:9001"
      - "9000:9000"
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data
    command: minio server /minio_data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  milvus:
    container_name: milvus-standalone
    image: milvusdb/milvus:v2.3.3
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      start_period: 90s
      timeout: 20s
      retries: 3
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - etcd
      - minio

  # ============================================================================
  # Alternative Vector DB - Weaviate (uncomment to use instead of Milvus)
  # ============================================================================
  # weaviate:
  #   container_name: weaviate
  #   image: semitechnologies/weaviate:1.23.7
  #   ports:
  #     - "8080:8080"
  #   environment:
  #     QUERY_DEFAULTS_LIMIT: 25
  #     AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
  #     PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
  #     DEFAULT_VECTORIZER_MODULE: 'none'
  #     ENABLE_MODULES: ''
  #     CLUSTER_HOSTNAME: 'node1'
  #   volumes:
  #     - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/weaviate:/var/lib/weaviate

  # ============================================================================
  # Redis - Caching Layer
  # ============================================================================
  redis:
    container_name: llm-redis
    image: redis:7.2-alpine
    ports:
      - "6379:6379"
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/redis:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================================
  # PostgreSQL - Metadata Storage
  # ============================================================================
  postgres:
    container_name: llm-postgres
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-llm_platform}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
    ports:
      - "5432:5432"
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/postgres:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================================
  # LLM Serving Platform
  # ============================================================================
  llm-server:
    container_name: llm-server
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - CUDA_VERSION=12.1.0
    image: llm-deployment-platform:latest
    ports:
      - "8000:8000"  # API port
      - "8001:8001"  # Prometheus metrics port
    environment:
      # LLM Configuration
      - LLM_MODEL_NAME=${LLM_MODEL_NAME:-mistralai/Mistral-7B-Instruct-v0.2}
      - LLM_MODEL_PATH=/models/llm
      - QUANTIZATION_METHOD=${QUANTIZATION_METHOD:-awq}
      - GPU_MEMORY_UTILIZATION=${GPU_MEMORY_UTILIZATION:-0.9}
      - MAX_MODEL_LENGTH=${MAX_MODEL_LENGTH:-4096}

      # API Configuration
      - API_HOST=0.0.0.0
      - API_PORT=8000
      - LOG_LEVEL=${LOG_LEVEL:-info}

      # Vector DB Configuration
      - VECTOR_DB_TYPE=${VECTOR_DB_TYPE:-milvus}
      - MILVUS_HOST=milvus
      - MILVUS_PORT=19530

      # Redis Configuration
      - REDIS_HOST=redis
      - REDIS_PORT=6379

      # PostgreSQL Configuration
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB:-llm_platform}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}

      # Monitoring
      - PROMETHEUS_ENABLED=true
      - PROMETHEUS_PORT=8001

      # GPU Configuration
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    volumes:
      - ./src:/app/src
      - ./prompts:/app/prompts
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/models:/models
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/data:/data
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/logs:/var/log/llm-platform
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      milvus:
        condition: service_healthy
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 180s  # LLM loading takes time

  # ============================================================================
  # Prometheus - Metrics Collection
  # ============================================================================
  prometheus:
    container_name: llm-prometheus
    image: prom/prometheus:v2.48.1
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/alerting/alerts.yml:/etc/prometheus/alerts.yml
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/prometheus:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    depends_on:
      - llm-server

  # ============================================================================
  # Grafana - Metrics Visualization
  # ============================================================================
  grafana:
    container_name: llm-grafana
    image: grafana/grafana:10.2.3
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/grafana:/var/lib/grafana
    depends_on:
      - prometheus

  # ============================================================================
  # Jaeger - Distributed Tracing (Optional)
  # ============================================================================
  jaeger:
    container_name: llm-jaeger
    image: jaegertracing/all-in-one:1.53
    ports:
      - "16686:16686"  # Jaeger UI
      - "4317:4317"    # OTLP gRPC receiver
      - "4318:4318"    # OTLP HTTP receiver
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    profiles:
      - tracing  # Only start with: docker-compose --profile tracing up

  # ============================================================================
  # NVIDIA GPU Exporter - GPU Metrics (Optional)
  # ============================================================================
  gpu-exporter:
    container_name: gpu-exporter
    image: utkuozdemir/nvidia_gpu_exporter:1.2.0
    ports:
      - "9835:9835"
    volumes:
      - /usr/lib/x86_64-linux-gnu/libnvidia-ml.so:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so
      - /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1
      - /usr/bin/nvidia-smi:/usr/bin/nvidia-smi
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu, utility]
    profiles:
      - gpu-monitoring

volumes:
  etcd:
  minio:
  milvus:
  redis:
  postgres:
  prometheus:
  grafana:
  models:
  data:
  logs:

networks:
  default:
    name: llm-network
    driver: bridge
