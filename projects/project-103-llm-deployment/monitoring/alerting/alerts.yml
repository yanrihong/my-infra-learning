groups:
  - name: llm_alerts
    interval: 30s
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: rate(llm_errors_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors/sec"

      # High latency
      - alert: HighLatency
        expr: histogram_quantile(0.95, llm_request_duration_seconds_bucket) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "P95 latency above threshold"
          description: "P95 latency is {{ $value }}s"

      # GPU memory high
      - alert: GPUMemoryHigh
        expr: llm_gpu_memory_used_bytes / llm_gpu_memory_total_bytes > 0.9
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "GPU memory usage high"
          description: "GPU {{$labels.gpu_id}} memory at {{ $value }}%"

      # TODO: Add more alerts
      # - Cost threshold exceeded
      # - Request queue too long
      # - Model not responding
