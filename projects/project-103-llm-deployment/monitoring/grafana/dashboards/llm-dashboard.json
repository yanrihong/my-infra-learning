{
  "dashboard": {
    "title": "LLM Inference Dashboard",
    "tags": ["llm", "inference", "gpu"],
    "timezone": "browser",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(llm_requests_total[5m])",
            "legendFormat": "{{status}}"
          }
        ]
      },
      {
        "title": "P95 Latency",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, llm_request_duration_seconds_bucket)",
            "legendFormat": "P95"
          }
        ]
      },
      {
        "title": "Tokens Per Second",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(llm_tokens_total{direction='output'}[1m])",
            "legendFormat": "Output tokens/s"
          }
        ]
      },
      {
        "title": "GPU Utilization",
        "type": "graph",
        "targets": [
          {
            "expr": "avg(llm_gpu_utilization_percent)",
            "legendFormat": "GPU {{gpu_id}}"
          }
        ]
      },
      {
        "title": "GPU Memory",
        "type": "graph",
        "targets": [
          {
            "expr": "llm_gpu_memory_used_bytes / 1024 / 1024 / 1024",
            "legendFormat": "GPU {{gpu_id}}"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(llm_errors_total[5m])",
            "legendFormat": "{{error_type}}"
          }
        ]
      },
      {
        "title": "Cost (USD)",
        "type": "singlestat",
        "targets": [
          {
            "expr": "llm_cost_usd_total",
            "legendFormat": "Total cost"
          }
        ]
      }
    ]
  }
}
